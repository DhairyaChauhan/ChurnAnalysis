{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "from IPython.display import display\n",
    "from time import strftime, gmtime\n",
    "import snowflake.connector\n",
    "import sagemaker\n",
    "from sagemaker import AlgorithmEstimator, get_execution_role\n",
    "from sagemaker.predictor import RealTimePredictor, csv_serializer, StringDeserializer\n",
    "from sagemaker.transformer import Transformer\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from snowflake.connector.pandas_tools import write_pandas\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "print(\"IAM role ARN: {}\".format(role))\n",
    "\n",
    "#S3 bucket\n",
    "bucket = '<<REPLACE WITH YOUR BUCKET NAME>>'\n",
    "prefix = 'churn-analytics'\n",
    "\n",
    "#Connecting to Snowflake\n",
    "ctx = snowflake.connector.connect(\n",
    "  user='<<User ID>>',\n",
    "  password='<<PASSWORD',\n",
    "  account='<<ACCOUNT>>',\n",
    "  warehouse='<<WAREHOUSE ID>>',\n",
    "  database='<<DATABASE NAME>>',\n",
    "  schema='<<SCHEMA NAME'\n",
    ")\n",
    "\n",
    "cs=ctx.cursor()\n",
    "allrows=cs.execute(\"\"\"select Cust_ID,STATE,ACCOUNT_LENGTH,AREA_CODE,PHONE,INTL_PLAN,VMAIL_PLAN,VMAIL_MESSAGE,\n",
    "                   DAY_MINS,DAY_CALLS,DAY_CHARGE,EVE_MINS,EVE_CALLS,EVE_CHARGE,NIGHT_MINS,NIGHT_CALLS,\n",
    "                   NIGHT_CHARGE,INTL_MINS,INTL_CALLS,INTL_CHARGE,CUSTSERV_CALLS,\n",
    "                   CHURN from CUSTOMER_CHURN \"\"\").fetchall()\n",
    "\n",
    "churn = pd.DataFrame(allrows)\n",
    "churn.columns=['Cust_id','State','Account Length','Area Code','Phone','Intl Plan', 'VMail Plan', 'VMail Message','Day Mins',\n",
    "            'Day Calls', 'Day Charge', 'Eve Mins', 'Eve Calls', 'Eve Charge', 'Night Mins', 'Night Calls','Night Charge',\n",
    "            'Intl Mins','Intl Calls','Intl Charge','CustServ Calls', 'Churn']\n",
    "\n",
    "pd.set_option('display.max_columns', 500)     # Make sure we can see all of the columns\n",
    "pd.set_option('display.max_rows', 10)         # Keep the output on one page\n",
    "churn\n",
    "\n",
    "\n",
    "# Frequency tables for each categorical feature\n",
    "for column in churn.select_dtypes(include=['object']).columns:\n",
    "    display(pd.crosstab(index=churn[column], columns='% observations', normalize='columns'))\n",
    "\n",
    "# Histograms for each numeric features\n",
    "display(churn.describe())\n",
    "%matplotlib inline\n",
    "hist = churn.hist(bins=30, sharey=True, figsize=(10, 10))\n",
    "\n",
    "churn = churn.drop('Phone', axis=1)\n",
    "churn['Area Code'] = churn['Area Code'].astype(object)\n",
    "\n",
    "\n",
    "for column in churn.select_dtypes(include=['object']).columns:\n",
    "    if column != 'Churn':\n",
    "        display(pd.crosstab(index=churn[column], columns=churn['Churn'], normalize='columns'))\n",
    "\n",
    "for column in churn.select_dtypes(exclude=['object']).columns:\n",
    "    print(column)\n",
    "    hist = churn[[column, 'Churn']].hist(by='Churn', bins=30)\n",
    "    plt.show()\n",
    "\n",
    "display(churn.corr())\n",
    "pd.plotting.scatter_matrix(churn, figsize=(18, 18))\n",
    "plt.show()\n",
    "\n",
    "churn = churn.drop(['Day Charge', 'Eve Charge', 'Night Charge', 'Intl Charge'], axis=1)\n",
    "\n",
    "#Splitting the data into training and test sets\n",
    "to_split_data = churn.drop(['Cust_id'], axis=1)\n",
    "train_data, test_data = np.split(to_split_data.sample(frac=1, random_state=1729), [int(0.9 * len(to_split_data))])\n",
    "train_data.to_csv('train.csv', header=True, index=False)\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 1000)\n",
    "display(train_data)\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "\n",
    "\n",
    "hyperparameters = {\n",
    "    #\"hyperparameters\": {\n",
    "    #    \"NN\":{\"num_epochs\": \"1\"}\n",
    "    #},\n",
    "    #\"auto_stack\": \"True\",\n",
    "    \"label\": \"Churn\"\n",
    "}\n",
    "\n",
    "compatible_training_instance_type='ml.m5.4xlarge' \n",
    "s3_input_train = sagemaker.s3_input(s3_data='s3://{}/{}/train'.format(bucket, prefix), content_type='csv')\n",
    "\n",
    "#Using AutoGLuon\n",
    "autogluon = AlgorithmEstimator(algorithm_arn=algorithm_arn, \n",
    "                                  role=role, \n",
    "                                  train_instance_count=1, \n",
    "                                  train_instance_type=compatible_training_instance_type, \n",
    "                                  sagemaker_session=sess, \n",
    "                                  base_job_name='autogluon',\n",
    "                                  hyperparameters=hyperparameters,\n",
    "                                  train_volume_size=100) \n",
    "\n",
    "autogluon.fit({'training': s3_input_train})\n",
    "\n",
    "#Batch Inference\n",
    "batch_input = churn.iloc[:,:-1]\n",
    "batch_input.to_csv('batch.csv', header=False, index=False)\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'batch/in/batch.csv')).upload_file('batch.csv')\n",
    "\n",
    "s3uri_batch_input ='s3://{}/{}/batch/in'.format(bucket, prefix)\n",
    "print('Batch Transform input S3 uri: {}'.format(s3uri_batch_input))\n",
    "\n",
    "s3uri_batch_output= 's3://{}/{}/batch/out'.format(bucket, prefix)\n",
    "print('Batch Transform output S3 uri: {}'.format(s3uri_batch_output))\n",
    "\n",
    "\n",
    "BATCH_INSTANCE_TYPE = 'ml.c5.xlarge'\n",
    "\n",
    "#Transformer object to run the batch process\n",
    "transformer = autogluon.transformer(instance_count=1,\n",
    "                                         strategy='SingleRecord',\n",
    "                                         assemble_with='Line',\n",
    "                                         instance_type= BATCH_INSTANCE_TYPE,\n",
    "                                         accept = 'text/csv',\n",
    "                                         output_path=s3uri_batch_output)\n",
    "    \n",
    "transformer.transform(s3uri_batch_input,\n",
    "                      split_type= 'Line',\n",
    "                      content_type= 'text/csv',   \n",
    "                      input_filter = \"$[1:]\",\n",
    "                      join_source = \"Input\",\n",
    "                      output_filter = \"$[0,-1]\")\n",
    "\n",
    "transformer.wait()\n",
    "\n",
    "#Creating a simple confusion matrix by comparing actual to precited values\n",
    "batched_churn_scores = pd.read_csv(s3uri_batch_output+'/batch.csv.out', usecols=[0,1], names=['id','scores'])\n",
    "batched_churn_scores['scores'] = (batched_churn_scores['scores'] == \"True.\").astype(int)\n",
    "#batched_churn_scores['Churn'] = (churn['Churn'] == \"True.\").astype(int)\n",
    "gt_df = pd.DataFrame((churn['Churn'] == \"True.\").astype(int)).reset_index(drop=True)\n",
    "\n",
    "results_df= pd.concat([gt_df,batched_churn_scores],axis=1)\n",
    "pd.crosstab(index=results_df['Churn'], columns=np.round(results_df['scores']), rownames=['actual'], colnames=['predictions'])\n",
    "\n",
    "\n",
    "#Upload churn score to Snowflake\n",
    "results_df.columns = ['CHURN_IN','CUST_ID','CHURN_SCORE']\n",
    "\n",
    "success, nchunks, nrows, _ = write_pandas(ctx, results_df, 'ML_RESULTS')\n",
    "\n",
    "display(nrows)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
